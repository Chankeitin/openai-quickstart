{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e2458f-d038-4845-93a0-d4ad830f9f90",
   "metadata": {},
   "source": [
    "# LangChain 核心模块学习：Chains\n",
    "\n",
    "对于简单的大模型应用，单独使用语言模型（LLMs）是可以的。\n",
    "\n",
    "**但更复杂的大模型应用需要将 `LLMs` 和 `Chat Models` 链接在一起 - 要么彼此链接，要么与其他组件链接。**\n",
    "\n",
    "LangChain 为这种“链式”应用程序提供了 `Chain` 接口。\n",
    "\n",
    "LangChain 以通用方式定义了 `Chain`，它是对组件进行调用序列的集合，其中可以包含其他链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24efe291-8745-4e78-bdb4-648e60d7bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (0.2.0)\n",
      "Collecting langchain\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/a7/23dd2a34aded62c6fe31918f306517a36b182e02780c8ea93e2af5ab4cd5/langchain-0.2.8-py3-none-any.whl (987 kB)\n",
      "     ---------------------------------------- 0.0/987.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/987.6 kB ? eta -:--:--\n",
      "     - ----------------------------------- 41.0/987.6 kB 487.6 kB/s eta 0:00:02\n",
      "     ---- ------------------------------- 122.9/987.6 kB 901.1 kB/s eta 0:00:01\n",
      "     --------- ---------------------------- 256.0/987.6 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 522.2/987.6 kB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  983.0/987.6 kB 3.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 987.6/987.6 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\administrator\\appdata\\roaming\\python\\python310\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.19 (from langchain)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a9/dd/e259bcdccd5f37a7302f2da774ce1bba818927caeb781993b7b17ed9a186/langchain_core-0.2.19-py3-none-any.whl (366 kB)\n",
      "     ---------------------------------------- 0.0/366.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 366.5/366.5 kB 23.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (0.1.65)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\administrator\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/12/87/ea668d9441ad831a80223d5a5c6c787d18b6094b00c67a179327ed47c838/langsmith-0.1.86-py3-none-any.whl (129 kB)\n",
      "     ---------------------------------------- 0.0/129.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 129.4/129.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\miniconda3\\envs\\langchain\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\administrator\\appdata\\roaming\\python\\python310\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (2.3)\n",
      "Installing collected packages: langsmith, langchain-core, langchain\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.65\n",
      "    Uninstalling langsmith-0.1.65:\n",
      "      Successfully uninstalled langsmith-0.1.65\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.1\n",
      "    Uninstalling langchain-core-0.2.1:\n",
      "      Successfully uninstalled langchain-core-0.2.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.0\n",
      "    Uninstalling langchain-0.2.0:\n",
      "      Successfully uninstalled langchain-0.2.0\n",
      "Successfully installed langchain-0.2.8 langchain-core-0.2.19 langsmith-0.1.86\n"
     ]
    }
   ],
   "source": [
    "! pip install -U langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a7df0-26c7-4eb8-92f1-cc54445cf507",
   "metadata": {},
   "source": [
    "## LLMChain\n",
    "\n",
    "LLMChain 是 LangChain 中最简单的链，作为其他复杂 Chains 和 Agents 的内部调用，被广泛应用。\n",
    "\n",
    "一个LLMChain由PromptTemplate和语言模型（LLM or Chat Model）组成。它使用直接传入（或 memory 提供）的 key-value 来规范化生成 Prompt Template（提示模板），并将生成的 prompt （格式化后的字符串）传递给大模型，并返回大模型输出。\n",
    "\n",
    "![](../images/llm_chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd5ca7-ca54-4701-919c-2857266caefc",
   "metadata": {},
   "source": [
    "## Router Chain: 实现条件判断的大模型调用\n",
    "\n",
    "\n",
    "这段代码构建了一个可定制的链路系统，用户可以提供不同的输入提示，并根据这些提示获取适当的响应。\n",
    "\n",
    "主要逻辑：从`prompt_infos`创建多个`LLMChain`对象，并将它们保存在一个字典中，然后创建一个默认的`ConversationChain`，最后创建一个带有路由功能的`MultiPromptChain`。\n",
    "\n",
    "![](../images/router_chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf8c391-9225-4e66-ad4d-d689b53a0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b5061c-391e-4762-91c7-73b57f4ab501",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"你是一位非常聪明的物理教授。\n",
    "你擅长以简洁易懂的方式回答关于物理的问题。\n",
    "当你不知道某个问题的答案时，你会坦诚承认。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"你是一位很棒的数学家。你擅长回答数学问题。\n",
    "之所以如此出色，是因为你能够将难题分解成各个组成部分，\n",
    "先回答这些组成部分，然后再将它们整合起来回答更广泛的问题。\n",
    "\n",
    "\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"你是一位深谙生命奥秘的生物学家，擅长以形象生动的比喻揭示生物界错综复杂的运作机制。\n",
    "你对科学的探索充满了智慧和洞见，同时保持着对未知的敬畏和不懈的好奇心，总是以谦逊的姿态迎接每一个新的科学发现。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "computer_template = \"\"\"你是一位精通算法奥秘的计算机学家，擅长用贴切的类比来阐述计算机科学中的复杂概念。\n",
    "你对技术的追求充满了洞察力和前瞻性，同时保持着对未知领域的谦逊态度和永不满足的好奇心，总是以开放的心态迎接每一次技术革新的挑战。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "chinese_literature_template = \"\"\"你是一位深谙汉语文化精髓的汉语言文学家，擅长用生动的故事来解析复杂的语言现象。\n",
    "你对文学的探索充满了洞察力和细腻的感知，同时保持着对语言奥妙的好奇心和谦逊的学习态度，总是以温文尔雅的姿态引领他人走进汉语言文学的博大精深。\n",
    "\n",
    "这是一个问题：\n",
    "{input}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ef1db6e-3da4-4f9b-9707-0f30aa293dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"物理\",\n",
    "        \"description\": \"适用于回答物理问题\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"数学\",\n",
    "        \"description\": \"适用于回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"生物\",\n",
    "        \"description\": \"适用于回答生物问题\",\n",
    "        \"prompt_template\": biology_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"计算机\",\n",
    "        \"description\": \"适用于回答计算机问题\",\n",
    "        \"prompt_template\": computer_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"汉语言文学\",\n",
    "        \"description\": \"适用于回答汉语言文学问题\",\n",
    "        \"prompt_template\": chinese_literature_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3983cafe-c2d5-4951-b779-88d844594777",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\",base_url=\"https://api.xiaoai.plus/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db8be9f0-1ac2-4ded-8950-6403cfa40004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的目标链字典，用于存放根据prompt_infos生成的LLMChain。\n",
    "destination_chains = {}\n",
    "\n",
    "# 遍历prompt_infos列表，为每个信息创建一个LLMChain。\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]  # 提取名称\n",
    "    prompt_template = p_info[\"prompt_template\"]  # 提取模板\n",
    "    # 创建PromptTemplate对象\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    # 使用上述模板和llm对象创建LLMChain对象\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    # 将新创建的chain对象添加到destination_chains字典中\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 创建一个默认的ConversationChain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae77b13a-2077-4e80-83f9-a2b1d8398461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "langchain.chains.conversation.base.ConversationChain"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa4a82-2d96-4124-8896-4e11e5d5c8e9",
   "metadata": {},
   "source": [
    "### 使用 LLMRouterChain 实现条件判断调用\n",
    "\n",
    "这段代码定义了一个chain对象（LLMRouterChain），该对象首先使用router_chain来决定哪个destination_chain应该被执行，如果没有合适的目标链，则默认使用default_chain。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c196e6c-e767-4d4f-8327-50ead641bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5ada86e-e430-412c-828d-b053b630f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从prompt_infos中提取目标信息并将其转化为字符串列表\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "# 使用join方法将列表转化为字符串，每个元素之间用换行符分隔\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "# 根据MULTI_PROMPT_ROUTER_TEMPLATE格式化字符串和destinations_str创建路由模板\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "# 创建路由的PromptTemplate\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c1013dc-ae1f-468d-96b3-4babe0d50d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['物理: 适用于回答物理问题', '数学: 适用于回答数学问题', '生物: 适用于回答生物问题', '计算机: 适用于回答计算机问题', '汉语言文学: 适用于回答汉语言文学问题']\n"
     ]
    }
   ],
   "source": [
    "print(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a85ef126-aca1-40c2-8e01-d15af5500785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物问题\n",
      "计算机: 适用于回答计算机问题\n",
      "汉语言文学: 适用于回答汉语言文学问题\n"
     ]
    }
   ],
   "source": [
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5db81fcb-704a-4250-a6b5-210e4be77af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f882244c-1fa6-4d74-a44c-578c9fb25e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "物理: 适用于回答物理问题\n",
      "数学: 适用于回答数学问题\n",
      "生物: 适用于回答生物问题\n",
      "计算机: 适用于回答计算机问题\n",
      "汉语言文学: 适用于回答汉语言文学问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2a482e4-5757-4295-a3d8-c3fdd1d4abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建MultiPromptChain对象，其中包含了路由链，目标链和默认链。\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "128bb7a0-b176-4b14-835e-8aaa723ab441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "物理: {'input': '黑体辐射是什么？?'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '黑体辐射是什么？?', 'text': '\\n\\n黑体辐射是一种理想化的物理现象，它指的是在温度为绝对零度时，物体所发出的电磁辐射。这种辐射的光谱分布与物体的温度有关，符合普朗克定律。黑体辐射在物理学中有很重要的作用，能够解释一些重要的现象，如热力学平衡、宇宙微波背景辐射等。'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"黑体辐射是什么？?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd869807-9cec-4bb2-9104-ecc4efce9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "数学: {'input': '40'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '40', 'text': '\\n这不是一个问题，这是一个数字。要成为一位优秀的数学家，你需要学习如何提出和解决问题，而不仅仅是回答给定的数字或方程式。数学是一门探索和解决问题的学科，它要求思考和创新能力。因此，要想成为一位优秀的数学家，你需要不断练习和挑战自己，学习如何应用数学知识来解决实际问题。'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.invoke(\n",
    "        \"大于40的第一个质数是多少，使得这个质数加一能被3整除？\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ad5dcb2-48c0-4d0f-b6cc-09ebcbdce75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd37e004-bb24-4929-992c-34407593d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "物理: {'input': '什么是黑洞？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '什么是黑洞？', 'text': '\\n黑洞是一种极端密度的天体，它的引力非常强大，以至于连光也无法逃脱。它的存在是由于质量非常巨大的恒星在死亡时产生的。当恒星的质量超过一定的极限，它会发生坍缩，形成一个极端密度的物体，即黑洞。由于黑洞的引力非常强大，它可以吞噬附近的物质，并且会不断吸收周围的物质增加自身的质量。目前，人类还无法直接观测黑洞，但通过间接的观测和理论计算，我们可以推测它们的存在。黑洞是宇宙中最神秘和令人着迷的天体之一，它们的研究也为我们揭示'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"黑洞是什么？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a51119ed-025f-48d7-ad81-cd9cdab7090f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbda2930-a0e6-48b2-8e02-4c3d792f0225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24d11e0f-d5ee-4086-9e1a-b21000232134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b6836f0-213d-4cac-abc9-3617831be3db",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "#### 扩展 Demo：实现生物、计算机和汉语言文学老师 PromptTemplates 及对应 Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c7edb0a-675d-40c0-9f5d-d58f0170ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "生物: {'input': '如何在细胞层面上解释生物体的衰老过程？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '如何在细胞层面上解释生物体的衰老过程？', 'text': '\\n\\n在细胞层面上，生物体的衰老过程可以解释为细胞功能逐渐衰退、损伤累积以及细胞死亡导致的。细胞的衰老可以分为两种类型：一种是自然衰老，即由于细胞内部的遗传信息不断累积错误导致细胞功能衰退；另一种是外在因素引起的衰老，比如环境因素、生活方式等。\\n\\n细胞衰老的主要原因之一是端粒缩短。端粒是位于染色体末端的一段DNA序列，它们的主要作用是保护染色体不受损伤。每当细胞分裂时，端粒都会缩短一小段，随着时间的推移，端粒变得越来'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"如何在细胞层面上解释生物体的衰老过程？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "计算机: {'input': '如何优化机器学习算法'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '如何优化机器学习算法', 'text': '的训练过程？\\n\\n这就像是一场马拉松比赛，机器学习算法就是参赛选手，而训练过程则是训练的训练路线。要想优化算法的训练过程，就需要从两个方向着手：一是提高选手的个人素质，二是优化训练的路线。\\n\\n首先，我们可以通过不断改进算法的设计和优化参数来提高选手的个人素质。就像一位运动员不断训练和调整自己的身体素质来提高自己的比赛水平一样，我们可以通过改善算法的结构和参数来提高其准确性和泛化能力。例如，使用更有效的模型架构、改进损失函数、选择更合适的优化器等等。\\n\\n其次，我们还可以通过优化训练的路线'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"如何优化机器学习算法以提高预测模型的准确性和效率？\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "汉语言文学: {'input': '如何分析《红楼梦》中的人物语言风格，以及这些风格如何反映出角色的性格和社会地位？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '如何分析《红楼梦》中的人物语言风格，以及这些风格如何反映出角色的性格和社会地位？', 'text': '\\n\\n《红楼梦》是中国古典文学中的经典之作，其中的人物形象和语言风格都具有深刻的文学意义。要分析《红楼梦》中的人物语言风格，首先需要对这部作品的背景和特点有一定的了解。\\n\\n《红楼梦》是一部具有浓厚社会色彩的长篇小说，它刻画了清朝贵族社会的生活和人物形象。在这个社会中，人们的身份地位和社会关系非常复杂，语言也成为了彰显身份和表达情感的重要手段。\\n\\n首先，我们可以从人物的语言习惯和用词特点来分析其语言风格。比如，贾宝玉作为贾府的少爷，他的语言中充满'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"如何分析《红楼梦》中的人物语言风格，以及这些风格如何反映出角色的性格和社会地位？\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
